{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18.330 Problem set 9 (spring 2020)\n",
    "\n",
    "## Submission deadline: 11:59pm on Tuesday, April 28\n",
    "\n",
    "### Exercise 1: Fourier series\n",
    "\n",
    "In lectures we saw that we can write a periodic function $f$ in the form\n",
    "\n",
    "$$\n",
    "f(x) = \\sum_{n = -N}^{N} \\hat{f}_n e^{inx}\n",
    "$$\n",
    "\n",
    "where $\\hat{f}_n := \\frac{1}{2 \\pi} \\int_0^{2\\pi} f(x) e^{-inx} \\mathrm{d}x$ if the period is $2\\pi$.\n",
    "\n",
    "The FFTW library uses a different convention, taking the period to be $1$.\n",
    "Suppose we sample a function at $N+1$ uniformly-spaced points between $[0, 1]$, obtaining values $f_0, f_1, \\ldots, f_{N}$, where $f_n := f(nh)$ with $h := \\frac{1}{N}$. By using the Fourier series we are implicitly assuming that $f$ is periodic, i.e. $f_0 = f_N$. Then\n",
    "$$\n",
    "f(x) = \\sum_{n = -\\frac{N}{2}}^{\\frac{N}{2}-1} \\hat{f}_n e^{2\\pi inx}\n",
    "$$\n",
    "where the Fourier coefficients are\n",
    "$$\\hat{f}_n := \\int_0^{1} f(x) \\, e^{-2\\pi inx} \\mathrm{d}x $$\n",
    "This is the convention we will use in this problem.\n",
    "\n",
    "1. Discretize the integral for the Fourier series coefficients using the trapezoidal rule using $N+1$ points. Using the assumption that $f_0 = f_N$ reduce this to a sum over $f_i$ for $i = 0, \\ldots, N-1$.\n",
    "\n",
    "    Implement this as a function `fourier_coefficients_trapezoidal(f::Vector)` where `f` is the vector of samples of $f_n$ for $n = 0, \\ldots, N-1$. Your function should return the coefficients for $\\hat{f}_k$ for $k = -\\frac{N}{2} , \\ldots,\\frac{N}{2} - 1$ as a vector.\n",
    "\n",
    "2. Consider the following three functions:\n",
    "\n",
    "    1. The sawtooth function\n",
    "    $$\n",
    "    f(x) = \\text{mod}(x, 1)\n",
    "    $$\n",
    "\n",
    "        (The function $\\text{mod}(x, 1)$ returns just the fractional part of a number.)\n",
    "\n",
    "    2. The \"W\" wave function\n",
    "    $$\n",
    "    g(x) = \\begin{cases} x & 0 \\le x < 0.5 \\\\  1 - x & 0.5 \\le x < 1 \\\\ g(\\text{mod}(x, 1)) & \\text{otherwise} \\end{cases}\n",
    "    $$\n",
    "\n",
    "    3. The function\n",
    "    $$\n",
    "    h(x) = \\exp(\\cos(2\\pi x))\n",
    "    $$\n",
    "\n",
    "    Plot them.\n",
    "\n",
    "    Given the properties of these functions, how would you expect their Fourier coefficients to decay?\n",
    "\n",
    "3. Take $N = 100$. Calculate $\\hat{f}$, $\\hat{g}$ and $\\hat{h}$ using your `fourier_ceofficients_trapezoidal` function. Plot the magnitude of the coefficients as a function of $n$ only for $n \\ge 0$. Do you see the expected behavior?\n",
    "\n",
    "4. How accurately does our function `fourier_coefficients_trapezoidal(f::Vector)` calculate the Fourier coefficients? Use the following  analytic solutions to calculate and plot the respective errors:\n",
    "\n",
    "    $$ \\hat{f}_0 = \\frac{1}{2} \\quad \\text{ and } \\quad \\hat{f}_n = \\frac{i}{2\\pi n} \\text{ for } n\\ne 0$$\n",
    "\n",
    "    $$ \\hat{g}_0 = \\frac{1}{4}; \\quad \\hat{g}_n = -\\frac{1}{\\pi^2 n^2} \\text{ for } n \\text{ odd}; \\quad \\text{ and } \\quad \\hat{g}_n = 0 \\text{ for } n \\text{ even}$$\n",
    "\n",
    "    $$ \\hat{h}_n = I_1(n) $$\n",
    "\n",
    "    where $I_1(n)$ is the modified Bessel function of the first kind, calculated in Julia as `besseli(n, 1)` using the `SpecialFunctions.jl` package.\n",
    "\n",
    "5.  Write a function `reconstruct_fourier_series(f̂s::Vector, xs::Vector)` which reconstructs `f(x)` from the Fourier series coefficients.\n",
    "\n",
    "    Make a plot of `||f(xt) - reconstruct_fourier_series(f̂s, xt)||/N` as the number of coefficients used $N$ is varied from $4 \\to 200$ for each of the functions.\n",
    "\n",
    "    Sample the reconstructed Fourier series at the points `xt = 0:0.001:1`. What do you see? Can you explain why?\n",
    "\n",
    "6. Make an interactive visualiztion that plots the following on the *same* axes:\n",
    "\n",
    "    (i) the points used to calculate the Fourier coefficients in `fourier_coefficients_rectangle`;\n",
    "\n",
    "    (ii) the reconstructed function from the Fourier coefficients, found using `reconstruct_fourier_series`; and\n",
    "\n",
    "     (iii) the true function as the number of points is varied from $N = 10:2:250$.\n",
    "\n",
    "     Does this help explain the results in [1.6]? In particular, what do you see for the sawtooth function? This is known as the **Gibbs phenomenon**, which occurs when a function is discontinuous.\n",
    "\n",
    "7. What is the operation count for your naive `fourier_coefficients_trapezoidal` function? In general this will not behave well as $N$ grows very large.\n",
    "\n",
    "    The FFT, however, can calculate this in $O(\\log(N))$ steps. The FFT implemented in `FFTW.jl` calculates\n",
    "    $$\n",
    "    \\hat{f}_n = \\sum_{k=0}^{N-1} f_k e^{-2\\pi i n k/N}\n",
    "    $$\n",
    "    for $n = 0:N-1$, which should be related to your discretization in [1.1].\n",
    "\n",
    "    Note that the $n$s are different here. But since $e^{-2\\pi i (n + lN) k/N} = e^{-2\\pi i l k} e^{-2\\pi i n k/N} = e^{-2\\pi i n k/N}$ we have the relationship\n",
    "    $\\hat{f}_{N/2 + i} = \\hat{f}_{-N/2 + i}$.\n",
    "\n",
    "    The FFT algorithm therefore outputs\n",
    "     $$\\hat{\\mathbf{f}} = [\\hat{f}_0, \\hat{f}_1, \\ldots, \\hat{f}_{N/2 - 1}, \\hat{f}_{-N/2}, \\hat{f}_{-N/2 + 1}, \\ldots, \\hat{f}_{-1}]$$\n",
    "\n",
    "     The FFTWpackage defines a function `fftshift` that shifts this vector to the form\n",
    "\n",
    "     $$\\hat{\\mathbf{f}} = [\\hat{f}_{-N/2}, \\hat{f}_{-N/2 + 1}, \\ldots, \\hat{f}_{-1}, \\hat{f}_0, \\hat{f}_1, \\ldots, \\hat{f}_{N/2 - 1}]$$\n",
    "\n",
    "8. Implement a function `fast_fourier_coefficients` that outputs the same results as `fourier_coefficients_trapezoidal`  but using the FFT from `FFTW.jl`.\n",
    "\n",
    "    Check that the output is the similar to before.\n",
    "\n",
    "    Time your two functions for $N = 2^10$. Is one faster than the other?\n",
    "\n",
    "    How large can you take `N` such that `fast_fourier_coefficients` runs for under 1 second? What about for `fourier_coefficients_trapezoidal`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Solving an ODE with a spectral method\n",
    "\n",
    "In this problem we will solve the boundary-value problem\n",
    "\n",
    "$$\n",
    "f'' = g\n",
    "$$\n",
    "\n",
    "with boundary conditions $f(0) = f(1) = 0$ by using a **spectral method**, i.e. by expanding in suitable basis functions.\n",
    "\n",
    "Due to the chosen boundary conditions we will consider the sine series\n",
    "$$f(x) = \\sum_{n = 1}^\\infty b_n \\sin(n\\pi x), $$\n",
    "which is the same as the Fourier series for an odd function.\n",
    "\n",
    "In practice we have to truncate the summation as\n",
    "$$f(x) = \\sum_{n = 1}^N b_n \\sin(n\\pi x) $$\n",
    "\n",
    "The coefficients are given by\n",
    "$$\n",
    "b_n = 2 \\int_0^1 f(x) \\sin(n\\pi x) \\mathrm{d}x\n",
    "$$\n",
    "Similarly to the DFT we discretize this using the rectangle rule to get the Discrete Sine Transform (DST):\n",
    "$$\n",
    "b_n = \\frac{2}{N} \\sum_{k=1}^{N-1} f(x) \\sin\\left(\\frac{nk\\pi}{N}\\right)\n",
    "$$\n",
    "This sum is implemented in julia using the `FFTW.jl` library (which you will need to install) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dst (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dst(x) = FFTW.r2r(x, FFTW.RODFT00) / length(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its inverse is given by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idst (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idst(x) = FFTW.r2r(x, FFTW.RODFT00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`r2r` stands for \"real to real\", meaning that the transform maps a real vector to a real vector. `RODFT00` is a symbol that selects one particular type of transform.]\n",
    "\n",
    "\n",
    "\n",
    "1. Assume that there is a solution of the form $\\tilde{f}(x) = \\sum_{n = 1}^N b_n \\sin(n\\pi x)$. Substitute this into the ODE $f''(x) = g(x)$ to show that $\\hat{\\tilde{f}}_n = -\\frac{\\hat{g}_n}{\\pi^2 n^2}$.\n",
    "\n",
    "2. We can therefore solve the ODE for $f$ by first calculating $\\hat{g}$ using the DST, then calculate $\\hat{f}_n$, and finally invert using the iDST.\n",
    "\n",
    "    Write a function `spectral_solver(b)` that does this to solve the ODE, where `b` is the discretized version of `g(x)`. Solve the ODE with $g(x) = \\sin(2\\pi x)$. Plot the result.\n",
    "\n",
    "    The right-hand side is given by\n",
    "\n",
    "    ```julia\n",
    "    h = 1 / N\n",
    "    b = sin.(2π * (h:h:1-h))\n",
    "    ```\n",
    "\n",
    "3. Calculate the error as a function of $N$ and plot it. What rate of convergence do you see?\n",
    "\n",
    "4. Generate the error plots again, now for the right-hand side $g(x) = \\exp(\\sin(2 \\pi x))-1$. Use the solution from your spectral solver with $N = 2^{13}$ as the true solution. Calculate the error for $N = 2^n$ for $n = 1\\to 12$. Some care is needed to make sure you use the correct points from the \"true\" solution for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Finding roots in a different way\n",
    "\n",
    "In class we defined the Chebyshev expansion of a function as\n",
    "$$\n",
    "f_N(x) = \\sum_{n = 0}^{N} c_n T_n(x)\n",
    "$$\n",
    "which is an $N$th-degree polynomial. The Chebyshev polynomials are defined as $T_n(x) = \\cos(n\\arccos(x))$.\n",
    "\n",
    "In general for a smooth function the Chebyshev series converges rapidly. We therefore expect that the roots of $f_N(x)$ should be close to the roots of $f(x)$, provided that $f_N$ is indeed a good approximation to $f$. We have already seen that we can find all the roots of a polynomial with various methods.\n",
    "\n",
    "The Chebyshev polynomials satisfy the following recurrence relation:\n",
    "$$\n",
    "T_{n+1}(x) = 2x \\, T_n(x) - T_{n-1}(x)\n",
    "$$\n",
    "\n",
    "We will use this to find the **companion matrix** for $f_N(x)$, from which we can find the roots of $f_N(x)$.\n",
    "\n",
    "1. Consider the polynomial $x T_n(x)$. This is a degree $n+1$ polynomial and hence can  be reexpanded in Chebyshev polynomials.\n",
    "\n",
    "    Consider the vector of Chebyshev polynomials\n",
    "    $$\n",
    "    \\mathbf{T}(x) = \\begin{bmatrix} T_0(x) \\\\ T_1(x) \\\\ \\vdots \\\\ T_{N-1}(x) \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "    Now we can write $x \\mathbf{T}(x) = M \\mathbf{T}(x) + k_N \\hat{e}_N T_N(x)$, where $M$ is an $(N-1) \\times (N-1)$ matrix. We need the $k_N$ term to account for the fact that $xT_{N-1}$ is a degree-$N$ polynomial. Here, $\\hat{e}_N$ is the standard basis vector with zeros everywhere except in the $N$th component.\n",
    "\n",
    "    Use the recurrence relation to find the form of $M$ and $k_N$.\n",
    "\n",
    "2. Verify what you found in [3.1] numerically when $N = 10$. Build the vector $\\mathbf{T}(x)$ for $x$ a random number in $[-1, 1]$. Compute $M$ and check that it gives $x\\mathbf{T}(x)$.\n",
    "\n",
    "3. This looks almost like an eigenvalue problem, except for the $T_N$ term. To remove this we can add and subtract $C f_N(x) \\hat{e}_N$ from the right-hand side. Writing $f_N(x) = c_N T_N(x) + \\sum_{n=0}^{N-1} c_n T_n(x)$, what value of $C$ should you choose so that\n",
    "\n",
    "    \\begin{align}\n",
    "    x \\mathbf{T}(x) &= M \\mathbf{T}(x) + Cf_N(x)\\hat{e}_N - C \\hat{e}_N \\sum_{n=0}^{N-1} c_n T_n(x) \\\\\n",
    "    & = \\tilde{M} \\mathbf{T}(x) + Cf_N(x)\\hat{e}_N\n",
    "    \\end{align}\n",
    "\n",
    "    What is the new matrix $\\tilde{M}$?\n",
    "\n",
    "4. This becomes an eigenvalue problem when $x$ is a root of $f_N(x)$. Therefore, the eigenvalues of $\\tilde{M}$ are the roots of $f_N$.\n",
    "\n",
    "    Write a function `buildM(c::Vector)` that constructs the matrix $\\tilde{M}$ from the coefficients in the Chebyshev expansion. Use this to write a `chebyshev_roots(c)` function that finds the roots of the polynomial defined using the Chebyshev coefficients `c`. Finally write a function `fN(x, c)` that calculates the series expansion to find $f_N(x)$ defined by the vector `c`.\n",
    "\n",
    "5. We can calculate Chebyshev coefficients using the `dct` functions in FFTW. We will use the Chebyshev points $x_n := \\cos(n \\pi/N)$ for $n = 0:N$. You can then calculate the Chebyshev coefficients using the following code:\n",
    "\n",
    "    ```julia\n",
    "    chebyshev_points(N) = cos.(π*(0:1:N)/N)\n",
    "\n",
    "    function chebyshev_coefficients(x)\n",
    "        N = length(x)\n",
    "        c = FFTW.r2r(x, FFTW.REDFT00)/(N-1)\n",
    "        c[1] /= 2\n",
    "        c[N] /=2\n",
    "\n",
    "        return c\n",
    "    end\n",
    "    ```\n",
    "\n",
    "6. Consider the polynomial $f(x) = x \\, (x-1/2)^2 \\, (x^2 - 1/9) \\, (x+1/4)$. Using $10$ Chebyshev points calculate the Chebyshev coefficients and then calculate the roots using `chebyshev_roots`. What do you see. What about multiplicities?\n",
    "\n",
    "7. Plot $f(x)$ and scatter plot the roots you find on top.\n",
    "\n",
    "8. Now consider solving the problem $\\exp(\\cos(4\\pi x)) = 1$. Using $N = 100$  points, alculate the Chebyshev coefficients for $g(x) = \\exp(\\cos(4\\pi x)) - 1$. Do they decay quickly? Use these to calculate the roots of $g(x)$. Plot $g(x)$ and `scatter` the roots you find on top. Do you find all the roots?\n",
    "\n",
    "    (Hint: you will find 100 eigenvalues. Only plot those that are real and lie between -1 and 1.)\n",
    "\n",
    "9. Make an interactive visualization as $N$ is varied between $N = 4:150$. Plot $g(x)$, the Cheyshev approximation to $g(x)$ using $N$ coefficients and the roots you find on the same axes. Comment on what you see.\n",
    "\n",
    "    At what value of $N$ do you find all the roots? Remember to plot only those roots that are real and between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Gram--Schmidt for polynomials\n",
    "\n",
    "In lectures we discussed treating the set of polynomials $\\{1, x, x^2, x^3, \\ldots \\}$ as the basis of a vector space with the inner product\n",
    "\n",
    "$$(f, g)_w = \\int_{a}^{b} f(x) g(x) w(x) \\mathrm{d}x$$\n",
    "\n",
    "We can therefore carry out Gram--Schmidt orthogonalization on these polynomials to generate a family of **orthogonal polynomials**.\n",
    "\n",
    "\n",
    "We will implemnent this using the `Polynomials.jl` package. Integrals can be performed using the `polyint(f, a, b)` function to integrate the polynomial $f$ from $a$ to $b$. Here, $f$, $g$ and $w$ should all be `Polynomials`.\n",
    "\n",
    "1. Write a function `gram_schmidt(vs::Vector, ip)` which accepts a vector of \"vectors\" in the vector space and the inner product on the vector spacce. For standard vectors this would be `dot(v1, v2)`. The function should implement the Gram--Schmidt algorithm and return a vector of the resulting orthonormal basis elements.\n",
    "\n",
    "2. Test your function for standard vectors `vs = [rand(10) for i = 1:10]` using `ip = dot`. To check everything went according to plan, form the matrix $Dp_{ij} = q_i \\cdot q_j$. If everything worked this should be the identity matrix.\n",
    "\n",
    "3. For polynomials we define the inner product\n",
    "$$\n",
    "(f, g)_w := \\int_{a}^{b} f(x) g(x) w(x) \\mathrm{d}x\n",
    "$$\n",
    "For Legendre polynomials we have $a = -1$ , $b = 1$,  and $w(x) = 1$.  Using the `Polynomials.jl` package, implement a function `legendre_inner_product(f, g)`. Use this to orthogonalize the vector of monomials up to order 7.\n",
    "\n",
    "4. Use the functions you found in [4.3] and your inner-product function, find the Legendre polynomial expansion coefficients for the function $f(x) = x \\, (x-1/2)^2 \\, (x^2 - 1/9) \\, (x+1/4)$.\n",
    "\n",
    "    Plot the reconstructed polynomial using the first $n$ coefficients for $N = 1:7$ and the true function on the same axes. What do you see? How good are the Legendre polynomials at approximating the function?\n",
    "\n",
    "5. Plot the Legendre and Chebyshev coefficients. How do their decay rates compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
